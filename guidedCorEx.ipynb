{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -m pip install corextopic\n",
    "# !python -m pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from corextopic import corextopic as ct\n",
    "from corextopic import vis_topic as vt # jupyter notebooks will complain matplotlib is being loaded twice\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import scipy.sparse as ss\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "newline = []\n",
    "\n",
    "textstring = ''\n",
    "with open('Hansard_preCovid.csv', 'r', encoding='utf-16-le') as inp, open('newtextfile.txt', 'w') as out:\n",
    "    for line in inp:\n",
    "      newline.append(re.findall(r'\"(.*)\"', line))\n",
    "      \n",
    "temp = pd.Series(newline)\n",
    "\n",
    "initialDF_preCovid = pd.DataFrame({'Text': temp})\n",
    "clearWords = stopwords.words('english')\n",
    "new_Stopwords = ['in', 'the', 'said', 'like','must', 'many', 'also']\n",
    "clearWords.extend(new_Stopwords)\n",
    "lemma= WordNetLemmatizer()\n",
    "initialDF_preCovid['Text'] = initialDF_preCovid['Text'].astype(str).str.lower()\n",
    "initialDF_preCovid['Text'] = initialDF_preCovid['Text'].str.replace(\"|\".join([r\"^.*?speaker,\", r\"^.*?chair,\" ]), ' ', regex=True)\n",
    "initialDF_preCovid['text_tokens'] = initialDF_preCovid['Text'].apply(word_tokenize)\n",
    "initialDF_preCovid['text_tokens'] = initialDF_preCovid['text_tokens'].apply(lambda x: [item for item in x if item not in clearWords])\n",
    "initialDF_preCovid['text_tokens'] = initialDF_preCovid['text_tokens'].apply(lambda x: [lemma.lemmatize(item) for item in x])\n",
    "# do we love me or what? isn't this join thing amazing?\n",
    "initialDF_preCovid['text_tokens'] = initialDF_preCovid['text_tokens'].apply(lambda x:' '.join([item for item in x if len(item)>3]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The topic model assumes input is in the form of a doc-word matrix, where rows are documents and columns are binary counts. We'll vectorize our data, take the top 20,000 words, and convert it to a sparse matrix to save on memory usage. Note, we use binary count vectors as input to the CorEx topic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 7778)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_features=20000, binary=True)\n",
    "doc_word = vectorizer.fit_transform(initialDF_preCovid['text_tokens'].astype(str))\n",
    "doc_word = ss.csr_matrix(doc_word)\n",
    "doc_word.shape # n_docs x m_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(305, 7396)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Get words that label the columns (needed to extract readable topics and make anchoring easier)\n",
    "words = list(np.asarray(vectorizer.get_feature_names_out()))\n",
    "not_digit_inds = [ind for ind,word in enumerate(words) if not word.isdigit()]\n",
    "doc_word = doc_word[:,not_digit_inds]\n",
    "words    = [word for ind,word in enumerate(words) if not word.isdigit()]\n",
    "\n",
    "doc_word.shape # n_docs x m_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CorEx topic model with 50 topics\n",
    "topic_model = ct.Corex(n_hidden=45, words=words, max_iter=1200, verbose=False, seed=11)\n",
    "topic_model.fit(doc_word, words=words);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: secretary,parliamentary,original,basis,comment,cent,remark,perspective,extensive,feedback\n",
      "1: citizenship,resident,refugee,immigration,visa,application,status,improving,permit,recommendation\n",
      "2: started,general,covered,exactly,caused,successive,discussed,transit,limited,steel\n",
      "3: important,want,issue,canada,right,house,thing,member,debate,today\n",
      "4: income,excluding,attendee,collected,output,summary,household,breach,bank,secret\n",
      "5: support,community,opportunity,economic,life,people,work,help,come,social\n",
      "6: mean,including,cost,provide,process,public,current,individual,benefit,government\n",
      "7: event,january,breakdown,visitor,july,list,disappointed,assigned,recipient,opinion\n",
      "8: witness,stated,brief,reference,recognized,oversight,wonder,task,dream,investigate\n",
      "9: market,relationship,domestic,implementation,consultation,partnership,operation,force,statement,affair\n",
      "10: address,funding,high,rate,toronto,young,common,addition,share,greater\n",
      "11: riding,spending,heritage,culture,associated,energy,relation,project,refused,natural\n",
      "12: european,corporate,strengthen,enforce,attractive,tool,freedom,producer,series,creative\n",
      "13: pipeline,morgan,kinder,massive,filled,green,british,cabinet,forced,object\n",
      "14: place,study,improve,information,created,meeting,supporting,service,number,area\n",
      "15: trade,agreement,international,product,nation,trading,partner,environmental,labour,generation\n",
      "16: provision,mechanism,europe,ceta,dispute,transparency,complaint,tariff,price,pharmaceutical\n",
      "17: health,standard,canadian,good,reason,level,free,allow,seek,safety\n",
      "18: need,policy,point,came,taking,difficult,called,particular,longer,kind\n",
      "19: change,private,clear,second,standing,passed,saying,different,fully,believe\n",
      "20: association,committee,regarding,official,organization,office,rejected,provided,group,message\n",
      "21: protection,purpose,agency,canadians,response,council,expense,diversity,proposal,president\n",
      "22: caregiver,live,family,processing,spouse,wait,backlog,month,reunite,child\n",
      "23: environment,drug,worker,indigenous,foreign,regulation,real,property,sustainable,following\n",
      "24: grow,great,proud,language,built,offer,diverse,english,contribute,chair\n",
      "25: knowledge,increasing,seafarer,eu,globally,threaten,reserve,royal,combat,rationale\n",
      "26: department,assistance,security,understanding,estimate,location,loan,quarter,title,constituency\n",
      "27: text,territory,grant,affected,code,tabled,aware,december,final,scotia\n",
      "28: atlantic,attract,pilot,immigrant,newcomer,economy,skill,succeed,success,strategy\n",
      "29: company,deal,loss,supply,port,concern,compensation,court,nafta,liberal\n",
      "30: small,business,past,leader,management,city,investment,middle,infrastructure,sector\n",
      "31: think,investor,situation,trying,quite,actually,problem,hear,asking,raise\n",
      "32: profit,content,risk,approved,sued,regional,recent,gone,present,issued\n",
      "33: food,agri,agriculture,october,conducted,saint,origin,contains,assessment,letter\n",
      "34: country,case,decision,democrat,corporation,require,used,legal,demand,return\n",
      "35: going,understand,vote,really,talking,constituent,pharmacare,away,interesting,potentially\n",
      "36: impact,claim,federal,according,remains,implement,needed,word,worth,analysis\n",
      "37: state,united,receive,settlement,various,period,pursue,seeking,financial,value\n",
      "38: boost,conclusion,contributed,advancing,achieved,friendly,protecting,accepting,item,penalty\n",
      "39: major,employment,easier,reality,higher,creating,enhance,outcome,raised,nearly\n",
      "40: strong,advantage,importance,represent,difference,prosperity,close,possible,citizen,stronger\n",
      "41: updated,stock,rich,monitor,incredible,equality,supportive,qu√©bec,profile,primary\n",
      "42: budget,highest,figure,mail,decide,represented,relief,located,director,foot\n",
      "43: applicant,disability,university,identified,medical,sponsor,police,celebrating,recognition,east\n",
      "44: wage,low,revenue,balance,completed,pressure,agree,intelligence,downward,planning\n"
     ]
    }
   ],
   "source": [
    "topics = topic_model.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('atlantic', 0.2118757731733022, 1.0),\n",
       " ('attract', 0.16952692055457777, 1.0),\n",
       " ('pilot', 0.16869213595442475, 1.0),\n",
       " ('immigrant', 0.14768737249103145, 1.0),\n",
       " ('newcomer', 0.1394224895690516, 1.0),\n",
       " ('economy', 0.13398757166665184, 1.0),\n",
       " ('skill', 0.1326815412570898, 1.0),\n",
       " ('succeed', 0.12517829234269348, 1.0),\n",
       " ('success', 0.12402910753850159, 1.0),\n",
       " ('strategy', 0.09858500971286509, 1.0),\n",
       " ('integrate', 0.09833859800300102, 1.0),\n",
       " ('successful', 0.08976984697373606, 1.0),\n",
       " ('skilled', 0.07629734250329366, 1.0),\n",
       " ('settle', 0.07416477287683357, 1.0),\n",
       " ('demographic', 0.0728065191219305, 1.0),\n",
       " ('update', 0.06813023204908782, 1.0),\n",
       " ('retain', 0.0648212125685644, 1.0),\n",
       " ('candidate', 0.06377351682295165, 1.0),\n",
       " ('talent', 0.05371150847705499, 1.0),\n",
       " ('driven', 0.04697691300293009, 1.0),\n",
       " ('reflects', 0.04697691300293009, 1.0),\n",
       " ('attracting', 0.04697691300293009, 1.0),\n",
       " ('stable', 0.04697606334236756, 1.0),\n",
       " ('changing', 0.04226155750538222, 1.0),\n",
       " ('broader', 0.041841002732485276, 1.0),\n",
       " ('quickly', 0.040841711166805246, 1.0),\n",
       " ('recruit', 0.03869358728411487, 1.0),\n",
       " ('named', 0.03869358728411487, 1.0),\n",
       " ('facilitating', 0.03869358728411487, 1.0),\n",
       " ('retention', 0.03869358728411487, 1.0),\n",
       " ('retiring', 0.03869358728411487, 1.0),\n",
       " ('root', 0.03869358728411487, 1.0),\n",
       " ('brunswick', 0.03470384162775166, 1.0),\n",
       " ('unlike', 0.034550358620093556, 1.0),\n",
       " ('remiss', 0.030484625166075335, 1.0),\n",
       " ('simpler', 0.030484625166075335, 1.0),\n",
       " ('fabric', 0.026829661762273003, 1.0),\n",
       " ('retire', 0.022348393643476763, 1.0),\n",
       " ('bridge', 0.022348393643476763, 1.0),\n",
       " ('baby', 0.022348393643476763, 1.0),\n",
       " ('apprentice', 0.022348393643476763, 1.0),\n",
       " ('altogether', 0.022348393643476763, 1.0),\n",
       " ('constantly', 0.022348393643476763, 1.0),\n",
       " ('pressing', 0.022348393643476763, 1.0),\n",
       " ('algonquin', 0.022348393643476763, 1.0),\n",
       " ('pan', 0.022348393643476763, 1.0),\n",
       " ('complemented', 0.022348393643476763, 1.0),\n",
       " ('expands', 0.022348393643476763, 1.0),\n",
       " ('historic', 0.020949814230009293, 1.0),\n",
       " ('team', 0.020715575108867575, 1.0),\n",
       " ('flourish', 0.019577853282406646, 1.0),\n",
       " ('possibly', 0.019550657972904225, 1.0),\n",
       " ('listened', 0.01954320877319335, 1.0),\n",
       " ('matched', 0.014283321241906868, 1.0),\n",
       " ('obstacle', 0.014283321241906868, 1.0),\n",
       " ('improves', 0.014283321241906868, 1.0),\n",
       " ('graduate', 0.014283321241906868, 1.0),\n",
       " ('individualized', 0.014283321241906868, 1.0),\n",
       " ('older', 0.01427831398651462, 1.0),\n",
       " ('edge', 0.012732365529593694, 1.0)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_model.get_topics(topic=28, n_words=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 important,worker,country,including,national,canada,issue,cost,temporary,member\n"
     ]
    }
   ],
   "source": [
    "anchor_words = [['worker', 'season', 'migrant', 'temporary']]\n",
    "anchored_topic_modelt = ct.Corex(n_hidden=45, seed=10)\n",
    "anchored_topic_modelt.fit(doc_word, words=words, anchors=anchor_words, anchor_strength=3)\n",
    "for n in range(len(anchor_words)):\n",
    "    topic_words,_,_ = zip(*anchored_topic_modelt.get_topics(topic=n))\n",
    "    print('{} '.format(n) + ','.join(topic_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('important', 0.3279770217456792, 1.0),\n",
       " ('worker', 0.3077435214220086, 1.0),\n",
       " ('country', 0.26203902728432243, 1.0),\n",
       " ('including', 0.25133926392305384, 1.0),\n",
       " ('national', 0.23786152180915576, 1.0),\n",
       " ('canada', 0.23007565540192806, 1.0),\n",
       " ('issue', 0.22830443586014124, 1.0),\n",
       " ('cost', 0.21909320644613098, 1.0),\n",
       " ('temporary', 0.21835984967742322, 1.0),\n",
       " ('member', 0.2163216584236027, 1.0),\n",
       " ('think', 0.21154574598563092, 1.0),\n",
       " ('house', 0.20963730869874195, 1.0),\n",
       " ('debate', 0.20793139471617786, 1.0),\n",
       " ('able', 0.20694796379720495, 1.0),\n",
       " ('canadian', 0.20536092176354057, 1.0),\n",
       " ('public', 0.20437173497488795, 1.0),\n",
       " ('reason', 0.2006563235347972, 1.0),\n",
       " ('benefit', 0.19084903190669306, 1.0),\n",
       " ('better', 0.19071994332578557, 1.0),\n",
       " ('term', 0.18559787299445824, 1.0),\n",
       " ('order', 0.1833953790058322, 1.0),\n",
       " ('access', 0.18339530930989992, 1.0),\n",
       " ('thing', 0.1823808387908236, 1.0),\n",
       " ('know', 0.1742817502271898, 1.0),\n",
       " ('business', 0.1734320319397817, 1.0),\n",
       " ('province', 0.1717248481927371, 1.0),\n",
       " ('effort', 0.16994244208736436, 1.0),\n",
       " ('million', 0.16402549327771954, 1.0),\n",
       " ('process', 0.16069210902503886, 1.0),\n",
       " ('example', 0.15681981171676476, 1.0),\n",
       " ('specific', 0.1562364532149914, 1.0),\n",
       " ('small', 0.1489744867219725, 1.0),\n",
       " ('ability', 0.14527110798140846, 1.0),\n",
       " ('rise', 0.1439350475354039, 1.0),\n",
       " ('international', 0.14383659111224123, 1.0),\n",
       " ('certain', 0.14227501599885917, 1.0),\n",
       " ('future', 0.1387170294339555, 1.0),\n",
       " ('deal', 0.13645343281198047, 1.0),\n",
       " ('pleased', 0.13620202786341748, 1.0),\n",
       " ('leader', 0.1296619004739723, 1.0),\n",
       " ('migrant', 0.125026330246756, 1.0),\n",
       " ('proposed', 0.12244308704484501, 1.0),\n",
       " ('legislation', 0.12244308704484501, 1.0),\n",
       " ('little', 0.12107482457189384, 1.0),\n",
       " ('getting', 0.11807029500295983, 1.0),\n",
       " ('bring', 0.11796756804843143, 1.0),\n",
       " ('course', 0.11678786901840205, 1.0),\n",
       " ('trying', 0.11674592335491167, 1.0),\n",
       " ('certainly', 0.11489208042747057, 1.0),\n",
       " ('employment', 0.11348118407591369, 1.0),\n",
       " ('common', 0.11310146261876412, 1.0),\n",
       " ('rate', 0.11310146261876412, 1.0),\n",
       " ('development', 0.11277934203072208, 1.0),\n",
       " ('used', 0.11056105825036582, 1.0),\n",
       " ('funding', 0.10954677642680832, 1.0),\n",
       " ('force', 0.10689102600232803, 1.0),\n",
       " ('particularly', 0.106891026002328, 1.0),\n",
       " ('believe', 0.10624127076977331, 1.0),\n",
       " ('respect', 0.10585041068182886, 1.0),\n",
       " ('start', 0.09843163624194326, 1.0),\n",
       " ('reality', 0.0968950313869964, 1.0),\n",
       " ('return', 0.09494558502043689, 1.0),\n",
       " ('various', 0.09494558502043689, 1.0),\n",
       " ('regarding', 0.09469749482133286, 1.0),\n",
       " ('sense', 0.09186945979664139, 1.0),\n",
       " ('position', 0.0900401482655011, 1.0),\n",
       " ('condition', 0.08921721065054146, 1.0),\n",
       " ('period', 0.08885462235185052, 1.0),\n",
       " ('paying', 0.08662926566460656, 1.0),\n",
       " ('income', 0.08448973503582101, 1.0),\n",
       " ('needed', 0.08437093417862403, 1.0),\n",
       " ('possible', 0.08373534893191277, 1.0),\n",
       " ('raised', 0.07983623364242756, 1.0),\n",
       " ('matter', 0.0797233291039479, 1.0),\n",
       " ('leave', 0.07879455629988054, 1.0),\n",
       " ('encourage', 0.07699268206839763, 1.0),\n",
       " ('approach', 0.07392969543610153, 1.0),\n",
       " ('recent', 0.07331318295246002, 1.0),\n",
       " ('real', 0.07331317571159855, 1.0),\n",
       " ('youth', 0.06979107296334407, 1.0),\n",
       " ('thinking', 0.06979107296334407, 1.0),\n",
       " ('meaningful', 0.06979107296334407, 1.0),\n",
       " ('spirit', 0.06979107296334407, 1.0),\n",
       " ('promote', 0.06979107296334407, 1.0),\n",
       " ('remember', 0.06979107296334407, 1.0),\n",
       " ('really', 0.06884008851268096, 1.0),\n",
       " ('foreign', 0.06710271042451309, 1.0),\n",
       " ('likely', 0.06361356359894282, 1.0),\n",
       " ('decided', 0.0623506164194016, 1.0),\n",
       " ('invest', 0.0623506164194016, 1.0),\n",
       " ('include', 0.062350616419401574, 1.0),\n",
       " ('source', 0.060446109609308345, 1.0),\n",
       " ('february', 0.060037699506207805, 1.0),\n",
       " ('expect', 0.05460523735353298, 1.0),\n",
       " ('tried', 0.0513869655523072, 1.0),\n",
       " ('considering', 0.0513869655523072, 1.0),\n",
       " ('origin', 0.0513869655523072, 1.0),\n",
       " ('equal', 0.04883846422604509, 1.0),\n",
       " ('brought', 0.04253899471341397, 1.0),\n",
       " ('restriction', 0.03932717962099854, 1.0)]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchored_topic_modelt.get_topics(topic=0, n_words=100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mid covid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialDF_midCovid= pd.read_csv('Hansard_mid_covid.csv', sep=',', encoding='utf-16-le')\n",
    "initialDF_midCovid.drop(['Publication', 'First Name', 'Last Name','Constituency', 'Province', 'Date', 'Time', 'Page'], axis=1)\n",
    "clearWords = stopwords.words('english')\n",
    "new_Stopwords = ['in', 'the', 'said', 'like','must', 'many', 'also']\n",
    "clearWords.extend(new_Stopwords)\n",
    "lemma= WordNetLemmatizer()\n",
    "\n",
    "initialDF_midCovid['Text'] = initialDF_midCovid['Text'].astype(str).str.lower()\n",
    "initialDF_midCovid['Text'] = initialDF_midCovid['Text'].str.replace(\"|\".join([r\"^.*?speaker,\", r\"^.*?chair,\" ]), ' ', regex=True)\n",
    "initialDF_midCovid['text_tokens'] = initialDF_midCovid['Text'].apply(word_tokenize)\n",
    "initialDF_midCovid['text_tokens'] = initialDF_midCovid['text_tokens'].apply(lambda x: [item for item in x if item not in clearWords])\n",
    "initialDF_midCovid['text_tokens'] = initialDF_midCovid['text_tokens'].apply(lambda x: [lemma.lemmatize(item) for item in x])\n",
    "# do we love me or what? isn't this join thing amazing?\n",
    "initialDF_midCovid['text_tokens'] = initialDF_midCovid['text_tokens'].apply(lambda x:' '.join([item for item in x if len(item)>3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', max_features=20000, binary=True)\n",
    "doc_word = vectorizer.fit_transform(initialDF_midCovid['text_tokens'].astype(str))\n",
    "doc_word = ss.csr_matrix(doc_word)\n",
    "doc_word.shape # n_docs x m_words\n",
    "\n",
    "# Get words that label the columns (needed to extract readable topics and make anchoring easier)\n",
    "words = list(np.asarray(vectorizer.get_feature_names_out()))\n",
    "not_digit_inds = [ind for ind,word in enumerate(words) if not word.isdigit()]\n",
    "doc_word = doc_word[:,not_digit_inds]\n",
    "words    = [word for ind,word in enumerate(words) if not word.isdigit()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "midcovid_unsup =  ct.Corex(n_hidden=60, words=words, max_iter=1200, verbose=False, seed=7)\n",
    "midcovid_unsup.fit(doc_word, words=words);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = midcovid_unsup.get_topics()\n",
    "for n,topic in enumerate(topics):\n",
    "    topic_words,_,_ = zip(*topic)\n",
    "    print('{}: '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "midcovid_unsup.get_topics(topic=55, n_words=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 migrant,workers,question,season,rising,proposes,floor,flexible,reminded,middle\n"
     ]
    }
   ],
   "source": [
    "anchor_words = [['workers', 'season', 'migrant']]\n",
    "anchored_midCovidt= ct.Corex(n_hidden=45, seed=10)\n",
    "anchored_midCovidt.fit(doc_word, words=words, anchors=anchor_words, anchor_strength=3)\n",
    "for n in range(len(anchor_words)):\n",
    "    topic_words,_,_ = zip(*anchored_midCovidt.get_topics(topic=n))\n",
    "    print('{} '.format(n) + ','.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('migrant', 0.2557059239256563, 1.0),\n",
       " ('workers', 0.16562050347123664, 1.0),\n",
       " ('question', 0.09220944512256433, 1.0),\n",
       " ('season', 0.07535253315843152, 1.0),\n",
       " ('rising', 0.07113384842447092, 1.0),\n",
       " ('proposes', 0.07113384842447092, 1.0),\n",
       " ('floor', 0.07113384842447092, 1.0),\n",
       " ('flexible', 0.06664869458465815, 1.0),\n",
       " ('reminded', 0.058501999858209294, 1.0),\n",
       " ('middle', 0.058501999858209294, 1.0),\n",
       " ('inclusion', 0.058501999858209294, 1.0),\n",
       " ('experienced', 0.058501999858209294, 1.0),\n",
       " ('communities', 0.058501999858209294, 1.0),\n",
       " ('legislative', 0.058501999858209294, 1.0),\n",
       " ('behaviour', 0.058501999858209294, 1.0),\n",
       " ('abuse', 0.058501999858209294, 1.0),\n",
       " ('airline', 0.058501999858209294, 1.0),\n",
       " ('river', 0.04605090308477814, 1.0),\n",
       " ('achieve', 0.04605090308477814, 1.0),\n",
       " ('section', 0.04605090308477814, 1.0),\n",
       " ('dangerous', 0.04605090308477814, 1.0),\n",
       " ('born', 0.04605090308477814, 1.0),\n",
       " ('dying', 0.04605090308477814, 1.0),\n",
       " ('permanently', 0.04605090308477814, 1.0),\n",
       " ('trend', 0.03377380312779652, 1.0),\n",
       " ('irrigation', 0.03377380312779652, 1.0),\n",
       " ('increasingly', 0.03377380312779652, 1.0),\n",
       " ('heritage', 0.03377380312779652, 1.0),\n",
       " ('oversight', 0.03377380312779652, 1.0),\n",
       " ('homes', 0.03377380312779652, 1.0),\n",
       " ('touch', 0.03377380312779652, 1.0),\n",
       " ('scotia', 0.03377380312779652, 1.0),\n",
       " ('fisher', 0.03377380312779652, 1.0),\n",
       " ('suspect', 0.03377380312779652, 1.0),\n",
       " ('chose', 0.03377380312779652, 1.0),\n",
       " ('rebuild', 0.03377380312779652, 1.0),\n",
       " ('downtown', 0.03377380312779652, 1.0),\n",
       " ('responder', 0.03377380312779652, 1.0),\n",
       " ('settle', 0.03377380312779652, 1.0),\n",
       " ('degree', 0.03377380312779652, 1.0),\n",
       " ('cusma', 0.03377380312779652, 1.0),\n",
       " ('nova', 0.03377380312779652, 1.0),\n",
       " ('promised', 0.03188736586067475, 1.0),\n",
       " ('christine', 0.02166438636310876, 1.0),\n",
       " ('nose', 0.02166438636310876, 1.0),\n",
       " ('compete', 0.02166438636310876, 1.0),\n",
       " ('practically', 0.02166438636310876, 1.0),\n",
       " ('prorogation', 0.02166438636310876, 1.0),\n",
       " ('satisfaction', 0.02166438636310876, 1.0),\n",
       " ('questioning', 0.02166438636310876, 1.0),\n",
       " ('ripple', 0.02166438636310876, 1.0),\n",
       " ('risen', 0.02166438636310876, 1.0),\n",
       " ('packed', 0.02166438636310876, 1.0),\n",
       " ('machinery', 0.02166438636310876, 1.0),\n",
       " ('justified', 0.02166438636310876, 1.0),\n",
       " ('tractor', 0.02166438636310876, 1.0),\n",
       " ('district', 0.02166438636310876, 1.0),\n",
       " ('drying', 0.02166438636310876, 1.0),\n",
       " ('dealt', 0.02166438636310876, 1.0),\n",
       " ('feeding', 0.02166438636310876, 1.0),\n",
       " ('changer', 0.02166438636310876, 1.0),\n",
       " ('busy', 0.02166438636310876, 1.0),\n",
       " ('fortunate', 0.02166438636310876, 1.0),\n",
       " ('severely', 0.02166438636310876, 1.0),\n",
       " ('geared', 0.02166438636310876, 1.0),\n",
       " ('disappointed', 0.02166438636310876, 1.0),\n",
       " ('greatly', 0.02166438636310876, 1.0),\n",
       " ('tourist', 0.02166438636310876, 1.0),\n",
       " ('hall', 0.02166438636310876, 1.0),\n",
       " ('times', 0.02166438636310876, 1.0),\n",
       " ('ignored', 0.02166438636310876, 1.0),\n",
       " ('things', 0.02166438636310876, 1.0),\n",
       " ('teacher', 0.02166438636310876, 1.0),\n",
       " ('roughly', 0.02166438636310876, 1.0),\n",
       " ('silence', 0.02166438636310876, 1.0),\n",
       " ('wiped', 0.02166438636310876, 1.0),\n",
       " ('underpaid', 0.02166438636310876, 1.0),\n",
       " ('costing', 0.021203600177661493, 1.0),\n",
       " ('love', 0.02114785479961777, 1.0),\n",
       " ('perspective', 0.015311297690430846, 1.0),\n",
       " ('raising', 0.01109920394932084, 1.0),\n",
       " ('warden', 0.009716739103843509, 1.0),\n",
       " ('santos', 0.009716739103843509, 1.0),\n",
       " ('nodding', 0.009716739103843509, 1.0),\n",
       " ('alberni', 0.009716739103843509, 1.0),\n",
       " ('courtenay', 0.009716739103843509, 1.0),\n",
       " ('dignified', 0.009716739103843509, 1.0),\n",
       " ('gary', 0.009716739103843509, 1.0),\n",
       " ('grieve', 0.009716739103843509, 1.0),\n",
       " ('guest', 0.009716739103843509, 1.0),\n",
       " ('hilda', 0.009716739103843509, 1.0),\n",
       " ('salmon', 0.009716739103843509, 1.0),\n",
       " ('broached', 0.009716739103843509, 1.0),\n",
       " ('kingsville', 0.009716739103843509, 1.0),\n",
       " ('leamington', 0.009716739103843509, 1.0),\n",
       " ('macdonald', 0.009716739103843509, 1.0),\n",
       " ('needs', 0.009716739103843509, 1.0),\n",
       " ('ordinated', 0.009716739103843509, 1.0),\n",
       " ('prioritizes', 0.009716739103843509, 1.0),\n",
       " ('amidst', 0.009716739103843509, 1.0)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anchored_midCovidt.get_topics(topic =0, n_words=100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c905b2281a0e18efbc7b52a3b445278246b1a358bdce3a3a9d510e8b53cc4ff4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
